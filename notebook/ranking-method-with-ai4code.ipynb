{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1214d9c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:08.303995Z",
     "iopub.status.busy": "2022-06-27T07:07:08.303270Z",
     "iopub.status.idle": "2022-06-27T07:07:10.695258Z",
     "shell.execute_reply": "2022-06-27T07:07:10.694184Z"
    },
    "papermill": {
     "duration": 2.409007,
     "end_time": "2022-06-27T07:07:10.698186",
     "exception": false,
     "start_time": "2022-06-27T07:07:08.289179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# let's get an idea of word frequency\n",
    "from collections import Counter\n",
    "\n",
    "# tool for text\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "data_dir = Path('../input/AI4Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686a1fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:10.723936Z",
     "iopub.status.busy": "2022-06-27T07:07:10.723016Z",
     "iopub.status.idle": "2022-06-27T07:07:10.728503Z",
     "shell.execute_reply": "2022-06-27T07:07:10.727711Z"
    },
    "papermill": {
     "duration": 0.020008,
     "end_time": "2022-06-27T07:07:10.730582",
     "exception": false,
     "start_time": "2022-06-27T07:07:10.710574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0ea869",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:10.755882Z",
     "iopub.status.busy": "2022-06-27T07:07:10.755149Z",
     "iopub.status.idle": "2022-06-27T07:07:14.378478Z",
     "shell.execute_reply": "2022-06-27T07:07:14.377408Z"
    },
    "papermill": {
     "duration": 3.638984,
     "end_time": "2022-06-27T07:07:14.381323",
     "exception": false,
     "start_time": "2022-06-27T07:07:10.742339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list of all the paths for all the training data\n",
    "paths_train = list((data_dir / 'train').glob('*.json'))\n",
    "\n",
    "# a list of all the notebook ids\n",
    "nb_ids = [str(path).split('/')[-1].split('.')[0] for path in paths_train]\n",
    "\n",
    "# create a df of the path and the notebook_id\n",
    "training_dict = {'path': paths_train, 'nb_id': nb_ids}\n",
    "training_paths_df = pd.DataFrame.from_dict(training_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ea5fac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:14.405228Z",
     "iopub.status.busy": "2022-06-27T07:07:14.404824Z",
     "iopub.status.idle": "2022-06-27T07:07:17.284225Z",
     "shell.execute_reply": "2022-06-27T07:07:17.283170Z"
    },
    "papermill": {
     "duration": 2.894732,
     "end_time": "2022-06-27T07:07:17.287236",
     "exception": false,
     "start_time": "2022-06-27T07:07:14.392504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the correct order of the cells\n",
    "df_orders = pd.read_csv(\n",
    "    data_dir / 'train_orders.csv',\n",
    "    index_col='id',\n",
    "    squeeze=True,\n",
    ").str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20da736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:17.312534Z",
     "iopub.status.busy": "2022-06-27T07:07:17.311700Z",
     "iopub.status.idle": "2022-06-27T07:07:17.354136Z",
     "shell.execute_reply": "2022-06-27T07:07:17.353233Z"
    },
    "papermill": {
     "duration": 0.058142,
     "end_time": "2022-06-27T07:07:17.356640",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.298498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "row = training_paths_df.iloc[idx]\n",
    "# retriveing a singel file and converting it to a dataframe\n",
    "disorganized_df = read_notebook(row['path'])\n",
    "cell_order = df_orders[row['nb_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "559fc2d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:17.382164Z",
     "iopub.status.busy": "2022-06-27T07:07:17.381485Z",
     "iopub.status.idle": "2022-06-27T07:07:17.387204Z",
     "shell.execute_reply": "2022-06-27T07:07:17.386042Z"
    },
    "papermill": {
     "duration": 0.021344,
     "end_time": "2022-06-27T07:07:17.389785",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.368441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d15fba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:17.414512Z",
     "iopub.status.busy": "2022-06-27T07:07:17.413411Z",
     "iopub.status.idle": "2022-06-27T07:07:17.421464Z",
     "shell.execute_reply": "2022-06-27T07:07:17.420647Z"
    },
    "papermill": {
     "duration": 0.022445,
     "end_time": "2022-06-27T07:07:17.423344",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.400899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank each of the cell in that specific notebook\n",
    "cell_ranks = get_ranks(cell_order, list(disorganized_df.index))\n",
    "# insert the ranks back into the dataframe\n",
    "disorganized_df.insert(0, 'rank', cell_ranks)\n",
    "\n",
    "organized_df = disorganized_df.copy()[['rank', 'cell_type', 'source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e7b0d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:17.447569Z",
     "iopub.status.busy": "2022-06-27T07:07:17.446874Z",
     "iopub.status.idle": "2022-06-27T07:07:17.453112Z",
     "shell.execute_reply": "2022-06-27T07:07:17.452277Z"
    },
    "papermill": {
     "duration": 0.020865,
     "end_time": "2022-06-27T07:07:17.455181",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.434316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "organized_df = disorganized_df.copy()[['rank', 'cell_type', 'source']]\n",
    "organized_df['rank_cleaned'] = [0] * len(organized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ebcae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:17.479338Z",
     "iopub.status.busy": "2022-06-27T07:07:17.478736Z",
     "iopub.status.idle": "2022-06-27T07:07:17.497230Z",
     "shell.execute_reply": "2022-06-27T07:07:17.496240Z"
    },
    "papermill": {
     "duration": 0.033334,
     "end_time": "2022-06-27T07:07:17.499557",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.466223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank_cleaned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8395ab7c</th>\n",
       "      <td>0</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport pandas as pd\\nimport uuid\\nimport...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebc844d6</th>\n",
       "      <td>1</td>\n",
       "      <td>code</td>\n",
       "      <td>df_train = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')\\ndf_train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49251f17</th>\n",
       "      <td>2</td>\n",
       "      <td>code</td>\n",
       "      <td>def bbox_inv_iou(boxA, boxB):\\n    \"\"\"Copied from: https://gist.github.com/meyerjo/dd3533edc97c81258898f60d8978eddc\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a6623e3</th>\n",
       "      <td>3</td>\n",
       "      <td>code</td>\n",
       "      <td>test_sequence_id = np.unique(df_train.sequence)[2]\\nprint(test_sequence_id)\\ntest_sequence_df = df_train[df_train.se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24e09d1a</th>\n",
       "      <td>4</td>\n",
       "      <td>code</td>\n",
       "      <td>seq_df_with_cots_ids, stats = find_unique_cots(\\n    test_sequence_df,\\n    dist_func=lambda boxA, boxB: bbox_center...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93e1713d</th>\n",
       "      <td>5</td>\n",
       "      <td>code</td>\n",
       "      <td>best_idx, best_row, most_cots = None, None, 0\\nfor idx, row in seq_df_with_cots_ids.iterrows():\\n    raw_annots = as...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d17c2682</th>\n",
       "      <td>6</td>\n",
       "      <td>code</td>\n",
       "      <td>def load_image(video_id, video_frame, image_dir):\\n    img_path = f'{image_dir}/video_{video_id}/{video_frame}.jpg'\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9fa9f6ca</th>\n",
       "      <td>7</td>\n",
       "      <td>code</td>\n",
       "      <td>from tqdm.auto import tqdm\\nimport subprocess\\n\\ndef make_video(df, video_name, image_dir):\\n    # partly borrowed f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714e15e7</th>\n",
       "      <td>8</td>\n",
       "      <td>code</td>\n",
       "      <td>from IPython.display import Video, display\\nVideo('test_video.mp4')</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4e5f080f</th>\n",
       "      <td>10</td>\n",
       "      <td>code</td>\n",
       "      <td>additional_columns_by_seqid = []\\n\\nfor sequence_id in np.unique(df_train.sequence):\\n    sequence_df = df_train[df_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444a12a4</th>\n",
       "      <td>11</td>\n",
       "      <td>code</td>\n",
       "      <td>df_train.join(pd.concat(additional_columns_by_seqid)).to_csv('train_with_cots_ids.csv')</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63a93277</th>\n",
       "      <td>9</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Generate videos for each sequence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rank cell_type                                                                                                                   source  rank_cleaned\n",
       "cell_id                                                                                                                                                        \n",
       "8395ab7c     0      code  import numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport pandas as pd\\nimport uuid\\nimport...             0\n",
       "ebc844d6     1      code                                     df_train = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')\\ndf_train             0\n",
       "49251f17     2      code  def bbox_inv_iou(boxA, boxB):\\n    \"\"\"Copied from: https://gist.github.com/meyerjo/dd3533edc97c81258898f60d8978eddc\\...             0\n",
       "3a6623e3     3      code  test_sequence_id = np.unique(df_train.sequence)[2]\\nprint(test_sequence_id)\\ntest_sequence_df = df_train[df_train.se...             0\n",
       "24e09d1a     4      code  seq_df_with_cots_ids, stats = find_unique_cots(\\n    test_sequence_df,\\n    dist_func=lambda boxA, boxB: bbox_center...             0\n",
       "93e1713d     5      code  best_idx, best_row, most_cots = None, None, 0\\nfor idx, row in seq_df_with_cots_ids.iterrows():\\n    raw_annots = as...             0\n",
       "d17c2682     6      code  def load_image(video_id, video_frame, image_dir):\\n    img_path = f'{image_dir}/video_{video_id}/{video_frame}.jpg'\\...             0\n",
       "9fa9f6ca     7      code  from tqdm.auto import tqdm\\nimport subprocess\\n\\ndef make_video(df, video_name, image_dir):\\n    # partly borrowed f...             0\n",
       "714e15e7     8      code                                                      from IPython.display import Video, display\\nVideo('test_video.mp4')             0\n",
       "4e5f080f    10      code  additional_columns_by_seqid = []\\n\\nfor sequence_id in np.unique(df_train.sequence):\\n    sequence_df = df_train[df_...             0\n",
       "444a12a4    11      code                                  df_train.join(pd.concat(additional_columns_by_seqid)).to_csv('train_with_cots_ids.csv')             0\n",
       "63a93277     9  markdown                                                                                      # Generate videos for each sequence             0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7a92e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:17.524786Z",
     "iopub.status.busy": "2022-06-27T07:07:17.524205Z",
     "iopub.status.idle": "2022-06-27T07:07:17.535152Z",
     "shell.execute_reply": "2022-06-27T07:07:17.534175Z"
    },
    "papermill": {
     "duration": 0.026225,
     "end_time": "2022-06-27T07:07:17.537738",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.511513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "organized_df['ranked_cleaned'] = np.where(\n",
    "organized_df['cell_type'] == 'code',\n",
    "organized_df.groupby(['cell_type']).cumcount().to_numpy() + 1,\n",
    "0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c193791d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:17.562529Z",
     "iopub.status.busy": "2022-06-27T07:07:17.562138Z",
     "iopub.status.idle": "2022-06-27T07:07:17.574734Z",
     "shell.execute_reply": "2022-06-27T07:07:17.573508Z"
    },
    "papermill": {
     "duration": 0.027886,
     "end_time": "2022-06-27T07:07:17.576970",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.549084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank_cleaned</th>\n",
       "      <th>ranked_cleaned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8395ab7c</th>\n",
       "      <td>0</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport pandas as pd\\nimport uuid\\nimport...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebc844d6</th>\n",
       "      <td>1</td>\n",
       "      <td>code</td>\n",
       "      <td>df_train = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')\\ndf_train</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49251f17</th>\n",
       "      <td>2</td>\n",
       "      <td>code</td>\n",
       "      <td>def bbox_inv_iou(boxA, boxB):\\n    \"\"\"Copied from: https://gist.github.com/meyerjo/dd3533edc97c81258898f60d8978eddc\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a6623e3</th>\n",
       "      <td>3</td>\n",
       "      <td>code</td>\n",
       "      <td>test_sequence_id = np.unique(df_train.sequence)[2]\\nprint(test_sequence_id)\\ntest_sequence_df = df_train[df_train.se...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24e09d1a</th>\n",
       "      <td>4</td>\n",
       "      <td>code</td>\n",
       "      <td>seq_df_with_cots_ids, stats = find_unique_cots(\\n    test_sequence_df,\\n    dist_func=lambda boxA, boxB: bbox_center...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93e1713d</th>\n",
       "      <td>5</td>\n",
       "      <td>code</td>\n",
       "      <td>best_idx, best_row, most_cots = None, None, 0\\nfor idx, row in seq_df_with_cots_ids.iterrows():\\n    raw_annots = as...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d17c2682</th>\n",
       "      <td>6</td>\n",
       "      <td>code</td>\n",
       "      <td>def load_image(video_id, video_frame, image_dir):\\n    img_path = f'{image_dir}/video_{video_id}/{video_frame}.jpg'\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9fa9f6ca</th>\n",
       "      <td>7</td>\n",
       "      <td>code</td>\n",
       "      <td>from tqdm.auto import tqdm\\nimport subprocess\\n\\ndef make_video(df, video_name, image_dir):\\n    # partly borrowed f...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714e15e7</th>\n",
       "      <td>8</td>\n",
       "      <td>code</td>\n",
       "      <td>from IPython.display import Video, display\\nVideo('test_video.mp4')</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4e5f080f</th>\n",
       "      <td>10</td>\n",
       "      <td>code</td>\n",
       "      <td>additional_columns_by_seqid = []\\n\\nfor sequence_id in np.unique(df_train.sequence):\\n    sequence_df = df_train[df_...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444a12a4</th>\n",
       "      <td>11</td>\n",
       "      <td>code</td>\n",
       "      <td>df_train.join(pd.concat(additional_columns_by_seqid)).to_csv('train_with_cots_ids.csv')</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63a93277</th>\n",
       "      <td>9</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Generate videos for each sequence</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rank cell_type                                                                                                                   source  rank_cleaned  ranked_cleaned\n",
       "cell_id                                                                                                                                                                        \n",
       "8395ab7c     0      code  import numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport pandas as pd\\nimport uuid\\nimport...             0               1\n",
       "ebc844d6     1      code                                     df_train = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')\\ndf_train             0               2\n",
       "49251f17     2      code  def bbox_inv_iou(boxA, boxB):\\n    \"\"\"Copied from: https://gist.github.com/meyerjo/dd3533edc97c81258898f60d8978eddc\\...             0               3\n",
       "3a6623e3     3      code  test_sequence_id = np.unique(df_train.sequence)[2]\\nprint(test_sequence_id)\\ntest_sequence_df = df_train[df_train.se...             0               4\n",
       "24e09d1a     4      code  seq_df_with_cots_ids, stats = find_unique_cots(\\n    test_sequence_df,\\n    dist_func=lambda boxA, boxB: bbox_center...             0               5\n",
       "93e1713d     5      code  best_idx, best_row, most_cots = None, None, 0\\nfor idx, row in seq_df_with_cots_ids.iterrows():\\n    raw_annots = as...             0               6\n",
       "d17c2682     6      code  def load_image(video_id, video_frame, image_dir):\\n    img_path = f'{image_dir}/video_{video_id}/{video_frame}.jpg'\\...             0               7\n",
       "9fa9f6ca     7      code  from tqdm.auto import tqdm\\nimport subprocess\\n\\ndef make_video(df, video_name, image_dir):\\n    # partly borrowed f...             0               8\n",
       "714e15e7     8      code                                                      from IPython.display import Video, display\\nVideo('test_video.mp4')             0               9\n",
       "4e5f080f    10      code  additional_columns_by_seqid = []\\n\\nfor sequence_id in np.unique(df_train.sequence):\\n    sequence_df = df_train[df_...             0              10\n",
       "444a12a4    11      code                                  df_train.join(pd.concat(additional_columns_by_seqid)).to_csv('train_with_cots_ids.csv')             0              11\n",
       "63a93277     9  markdown                                                                                      # Generate videos for each sequence             0               0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7b07922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:17.602120Z",
     "iopub.status.busy": "2022-06-27T07:07:17.601679Z",
     "iopub.status.idle": "2022-06-27T07:07:17.610325Z",
     "shell.execute_reply": "2022-06-27T07:07:17.609308Z"
    },
    "papermill": {
     "duration": 0.024014,
     "end_time": "2022-06-27T07:07:17.612413",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.588399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PythonDataset(Dataset):\n",
    "    def __init__(self, df, df_orders):\n",
    "        self.df = df\n",
    "        self.df_orders = df_orders\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = training_paths_df.iloc[idx]\n",
    "        # retriveing a singel file and converting it to a dataframe\n",
    "        disorganized_df = read_notebook(row['path'])\n",
    "        cell_order = df_orders[row['nb_id']]\n",
    "        \n",
    "        # rank each of the cell in that specific notebook\n",
    "        cell_ranks = get_ranks(cell_order, list(disorganized_df.index))\n",
    "        # insert the ranks back into the dataframe\n",
    "        disorganized_df.insert(0, 'rank', cell_ranks)\n",
    "\n",
    "        organized_df = disorganized_df.copy()[['rank', 'cell_type', 'source']]\n",
    "        organized_df['ranked_cleaned'] = np.where(\n",
    "                                            organized_df['cell_type'] == 'code',\n",
    "                                            organized_df.groupby(['cell_type']).cumcount().to_numpy() + 1,\n",
    "                                            0,)\n",
    "        return organized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2852d85",
   "metadata": {
    "papermill": {
     "duration": 0.011431,
     "end_time": "2022-06-27T07:07:17.635261",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.623830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aed23b7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:17.660781Z",
     "iopub.status.busy": "2022-06-27T07:07:17.660069Z",
     "iopub.status.idle": "2022-06-27T07:07:17.664390Z",
     "shell.execute_reply": "2022-06-27T07:07:17.663703Z"
    },
    "papermill": {
     "duration": 0.019285,
     "end_time": "2022-06-27T07:07:17.666290",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.647005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "whole_train = training_paths_df.iloc[:50, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52315531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:17.691306Z",
     "iopub.status.busy": "2022-06-27T07:07:17.690734Z",
     "iopub.status.idle": "2022-06-27T07:07:17.694655Z",
     "shell.execute_reply": "2022-06-27T07:07:17.693905Z"
    },
    "papermill": {
     "duration": 0.019055,
     "end_time": "2022-06-27T07:07:17.696665",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.677610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "whole_train_ds = PythonDataset(whole_train, df_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "363cb216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:17.722636Z",
     "iopub.status.busy": "2022-06-27T07:07:17.722018Z",
     "iopub.status.idle": "2022-06-27T07:07:18.866412Z",
     "shell.execute_reply": "2022-06-27T07:07:18.865390Z"
    },
    "papermill": {
     "duration": 1.160967,
     "end_time": "2022-06-27T07:07:18.869075",
     "exception": false,
     "start_time": "2022-06-27T07:07:17.708108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp= spacy.load('en_core_web_sm', disable = ['ner', 'parser'])\n",
    "def clean_text(df, nlp, column):\n",
    "    rows = []\n",
    "    for idx in range(len(df)):\n",
    "        row = df.iloc[idx].copy()\n",
    "\n",
    "        # first we remove numeric characters and lowercase everything\n",
    "        cleaned_review = re.sub(\"[^A-Za-z']+\", ' ', row[column].replace('<br />', ' ')).lower()\n",
    "        # we let spaCy tokenize the text for us\n",
    "        tokenized_review = nlp(cleaned_review)\n",
    "        cleaned_tokenized = [token.lemma_ for token in tokenized_review]\n",
    "        cleaned_tokenized = [token for token in cleaned_tokenized if len(token)>1]\n",
    "\n",
    "        if len(cleaned_tokenized) >= 1:\n",
    "            row['cleaned'] = ' '.join(cleaned_tokenized)\n",
    "\n",
    "        rows.append(row)\n",
    "    data = pd.DataFrame(rows)\n",
    "    data = data.reset_index()\n",
    "    idx_nans = np.where(data['cleaned'].isna())[0]\n",
    "    data = data.drop(idx_nans)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1065458d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:18.894449Z",
     "iopub.status.busy": "2022-06-27T07:07:18.893747Z",
     "iopub.status.idle": "2022-06-27T07:07:18.899101Z",
     "shell.execute_reply": "2022-06-27T07:07:18.898193Z"
    },
    "papermill": {
     "duration": 0.020578,
     "end_time": "2022-06-27T07:07:18.901295",
     "exception": false,
     "start_time": "2022-06-27T07:07:18.880717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_max_length(data):\n",
    "    max_length = 0\n",
    "    for i in range(len(data)):\n",
    "        row = data.iloc[i]['cleaned']\n",
    "        length = len(row.split())\n",
    "\n",
    "        if length > max_length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36000c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:18.926146Z",
     "iopub.status.busy": "2022-06-27T07:07:18.925312Z",
     "iopub.status.idle": "2022-06-27T07:07:18.931175Z",
     "shell.execute_reply": "2022-06-27T07:07:18.930269Z"
    },
    "papermill": {
     "duration": 0.020586,
     "end_time": "2022-06-27T07:07:18.933244",
     "exception": false,
     "start_time": "2022-06-27T07:07:18.912658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_whole_df(df, df_ds):\n",
    "    final_df = None\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        temp_df = df_ds[i]\n",
    "        cleaned_df = clean_text(temp_df, nlp, 'source')\n",
    "\n",
    "        if i == 0:\n",
    "            final_df = cleaned_df\n",
    "        final_df = pd.concat([final_df, cleaned_df])\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1def6486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:18.957895Z",
     "iopub.status.busy": "2022-06-27T07:07:18.957490Z",
     "iopub.status.idle": "2022-06-27T07:07:18.964679Z",
     "shell.execute_reply": "2022-06-27T07:07:18.963911Z"
    },
    "papermill": {
     "duration": 0.021934,
     "end_time": "2022-06-27T07:07:18.966619",
     "exception": false,
     "start_time": "2022-06-27T07:07:18.944685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_word_dict(cleaned_df):\n",
    "    sentences = [string.split(' ') for string in list(cleaned_df['cleaned'])]\n",
    "    word_freq = Counter([token for string in sentences for token in string]).most_common()\n",
    "    word_freq_dict = dict(word_freq)\n",
    "    \n",
    "    min_freq = 5\n",
    "    word_dict = {}\n",
    "\n",
    "    # sending all the unknowns to 0\n",
    "    i = 1\n",
    "    for word in word_freq_dict:\n",
    "        if word_freq_dict[word] > min_freq:\n",
    "            word_dict[word] = i\n",
    "            i += 1\n",
    "        else:\n",
    "            word_dict[word] = 0\n",
    "    \n",
    "    # dictionary length        \n",
    "    dict_length = max(word_dict.values()) + 1\n",
    "    \n",
    "    return dict_length, word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "829023fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:18.991897Z",
     "iopub.status.busy": "2022-06-27T07:07:18.991201Z",
     "iopub.status.idle": "2022-06-27T07:07:31.557010Z",
     "shell.execute_reply": "2022-06-27T07:07:31.555877Z"
    },
    "papermill": {
     "duration": 12.581705,
     "end_time": "2022-06-27T07:07:31.559639",
     "exception": false,
     "start_time": "2022-06-27T07:07:18.977934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:12<00:00,  4.09it/s]\n"
     ]
    }
   ],
   "source": [
    "final_train = preprocess_whole_df(whole_train, whole_train_ds)\n",
    "dict_length, word_dict = make_word_dict(final_train)\n",
    "max_length = find_max_length(final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba84f135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:31.592354Z",
     "iopub.status.busy": "2022-06-27T07:07:31.591591Z",
     "iopub.status.idle": "2022-06-27T07:07:31.601925Z",
     "shell.execute_reply": "2022-06-27T07:07:31.600739Z"
    },
    "papermill": {
     "duration": 0.02943,
     "end_time": "2022-06-27T07:07:31.604463",
     "exception": false,
     "start_time": "2022-06-27T07:07:31.575033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PythonDataset2(Dataset):\n",
    "    def __init__(self, df, word_dict, max_length):\n",
    "        self.df = df\n",
    "        self.word_dict = word_dict\n",
    "        self.max_len = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "#         print(row)\n",
    "        content = row['cleaned'].split(' ')\n",
    "        \n",
    "        # find the idx that is asscoiated with the particular word\n",
    "        content_idxs = [self.word_dict[word] for word in content]\n",
    "        # front pad the sentence \n",
    "        cleaned_content_arr = np.array(content_idxs)\n",
    "        zeros_arr = np.zeros(max_length - len(content))\n",
    "        padded_arr = np.concatenate([zeros_arr, cleaned_content_arr])\n",
    "        \n",
    "        x = torch.LongTensor(padded_arr) \n",
    "        x2 = torch.tensor(row['ranked_cleaned']).float()\n",
    "        y = torch.tensor(row['rank']).float()\n",
    "        \n",
    "        # embedding likes long tensors\n",
    "        return x, x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93bea71d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:31.636450Z",
     "iopub.status.busy": "2022-06-27T07:07:31.636070Z",
     "iopub.status.idle": "2022-06-27T07:07:31.642099Z",
     "shell.execute_reply": "2022-06-27T07:07:31.640914Z"
    },
    "papermill": {
     "duration": 0.025053,
     "end_time": "2022-06-27T07:07:31.644489",
     "exception": false,
     "start_time": "2022-06-27T07:07:31.619436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = int(final_train.shape[0] * 0.8)\n",
    "train = final_train.iloc[:N, :]\n",
    "val = final_train.iloc[N:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a16b6d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:31.676645Z",
     "iopub.status.busy": "2022-06-27T07:07:31.676070Z",
     "iopub.status.idle": "2022-06-27T07:07:31.682676Z",
     "shell.execute_reply": "2022-06-27T07:07:31.681798Z"
    },
    "papermill": {
     "duration": 0.025233,
     "end_time": "2022-06-27T07:07:31.684945",
     "exception": false,
     "start_time": "2022-06-27T07:07:31.659712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1840, 6), (460, 6))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c9e6b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:31.717085Z",
     "iopub.status.busy": "2022-06-27T07:07:31.716430Z",
     "iopub.status.idle": "2022-06-27T07:07:31.722544Z",
     "shell.execute_reply": "2022-06-27T07:07:31.721740Z"
    },
    "papermill": {
     "duration": 0.024951,
     "end_time": "2022-06-27T07:07:31.724954",
     "exception": false,
     "start_time": "2022-06-27T07:07:31.700003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = PythonDataset2(train, word_dict, max_length)\n",
    "val_ds = PythonDataset2(val, word_dict, max_length)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=10, shuffle=True)\n",
    "val_dl = DataLoader(train_ds, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c74ce805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:31.756889Z",
     "iopub.status.busy": "2022-06-27T07:07:31.756477Z",
     "iopub.status.idle": "2022-06-27T07:07:31.761227Z",
     "shell.execute_reply": "2022-06-27T07:07:31.760085Z"
    },
    "papermill": {
     "duration": 0.023175,
     "end_time": "2022-06-27T07:07:31.763301",
     "exception": false,
     "start_time": "2022-06-27T07:07:31.740126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0942ce23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:31.795564Z",
     "iopub.status.busy": "2022-06-27T07:07:31.794927Z",
     "iopub.status.idle": "2022-06-27T07:07:31.804624Z",
     "shell.execute_reply": "2022-06-27T07:07:31.803746Z"
    },
    "papermill": {
     "duration": 0.02866,
     "end_time": "2022-06-27T07:07:31.806899",
     "exception": false,
     "start_time": "2022-06-27T07:07:31.778239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vanilla RNN using nn.RNN\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, dict_length, max_length, emb_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        # embed the words\n",
    "        self.emb = nn.Embedding(dict_length, emb_size, padding_idx=0)\n",
    "        # pass through an LSTM\n",
    "        # RNN doesn't care about length of sequence\n",
    "        # RNN does care about the size of the word embedding\n",
    "        # hidden size dictates dimension of output of RN\n",
    "#         self.linear = nn.Linear(emb_size, hidden_size)   \n",
    "        \n",
    "        self.linear2 = nn.Linear((max_length*emb_size)+1, output_size)\n",
    "\n",
    "    def forward(self, x, x2):\n",
    "        \n",
    "        # RNN layer outputs a tuple, the output and the final hidden state\n",
    "        # taking the final hidden state as output\n",
    "#         print('-------', x.size(), max_length)\n",
    "        x = self.emb(x)\n",
    "        x = x.view(x.shape[0],x.shape[1]*x.shape[-1])\n",
    "\n",
    "        x2 = x2.unsqueeze(1)\n",
    "#         print(x.size(), x2.size())\n",
    "        X = torch.cat((x,x2), 1)\n",
    "#         print('-------', X.size)\n",
    "#         out = self.linear(X)\n",
    "#         out = F.relu(out)\n",
    "        out = self.linear2(X)\n",
    "#         X = F.relu(X)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65202292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:31.839096Z",
     "iopub.status.busy": "2022-06-27T07:07:31.838020Z",
     "iopub.status.idle": "2022-06-27T07:07:31.850506Z",
     "shell.execute_reply": "2022-06-27T07:07:31.849504Z"
    },
    "papermill": {
     "duration": 0.031243,
     "end_time": "2022-06-27T07:07:31.853143",
     "exception": false,
     "start_time": "2022-06-27T07:07:31.821900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RNN(dict_length, max_length, 7,5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "580ef900",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:31.888162Z",
     "iopub.status.busy": "2022-06-27T07:07:31.887088Z",
     "iopub.status.idle": "2022-06-27T07:07:31.895052Z",
     "shell.execute_reply": "2022-06-27T07:07:31.894128Z"
    },
    "papermill": {
     "duration": 0.029176,
     "end_time": "2022-06-27T07:07:31.897398",
     "exception": false,
     "start_time": "2022-06-27T07:07:31.868222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_pass(model, dataloader, optimizer,lossFun, backwards=True, print_loss=False):\n",
    "    \n",
    "    if backwards == True:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for x, x2, y in tqdm(dataloader):\n",
    "        \n",
    "        y_pred = model(x, x2)\n",
    "#         y_pred = y_pred.detach().numpy()\n",
    "#         y = y.detach().numpy()\n",
    "        loss = lossFun(y_pred, y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if backwards == True:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    if print_loss == True:\n",
    "        print(avg_loss)\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d76107c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:31.930715Z",
     "iopub.status.busy": "2022-06-27T07:07:31.929957Z",
     "iopub.status.idle": "2022-06-27T07:07:42.013793Z",
     "shell.execute_reply": "2022-06-27T07:07:42.012647Z"
    },
    "papermill": {
     "duration": 10.103637,
     "end_time": "2022-06-27T07:07:42.016645",
     "exception": false,
     "start_time": "2022-06-27T07:07:31.913008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cb66497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:42.049088Z",
     "iopub.status.busy": "2022-06-27T07:07:42.048679Z",
     "iopub.status.idle": "2022-06-27T07:07:43.454281Z",
     "shell.execute_reply": "2022-06-27T07:07:43.453032Z"
    },
    "papermill": {
     "duration": 1.425276,
     "end_time": "2022-06-27T07:07:43.457382",
     "exception": false,
     "start_time": "2022-06-27T07:07:42.032106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/184 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 11/184 [00:00<00:01, 109.37it/s]\u001b[A\n",
      " 20%|██        | 37/184 [00:00<00:00, 194.71it/s]\u001b[A\n",
      " 34%|███▍      | 63/184 [00:00<00:00, 223.12it/s]\u001b[A\n",
      " 48%|████▊     | 89/184 [00:00<00:00, 234.81it/s]\u001b[A\n",
      " 62%|██████▎   | 115/184 [00:00<00:00, 243.40it/s]\u001b[A\n",
      " 76%|███████▌  | 140/184 [00:00<00:00, 241.38it/s]\u001b[A\n",
      "100%|██████████| 184/184 [00:00<00:00, 232.98it/s]\n",
      "\n",
      "  0%|          | 0/184 [00:00<?, ?it/s]\u001b[A\n",
      " 16%|█▌        | 29/184 [00:00<00:00, 284.20it/s]\u001b[A\n",
      " 32%|███▏      | 59/184 [00:00<00:00, 292.16it/s]\u001b[A\n",
      " 50%|█████     | 92/184 [00:00<00:00, 306.00it/s]\u001b[A\n",
      " 68%|██████▊   | 125/184 [00:00<00:00, 313.47it/s]\u001b[A\n",
      "100%|██████████| 184/184 [00:00<00:00, 310.83it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1478.8955981835074 760.0424811710482\n",
      "Train Loss-1478.8956 Validation Loss-760.0425 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lossFun = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    print('Epoch: ', epoch)\n",
    "\n",
    "    train_loss = one_pass(model, train_dl, optimizer, lossFun, backwards=True, print_loss=False)\n",
    "\n",
    "    val_loss = one_pass(model, val_dl, optimizer, lossFun, backwards=False, print_loss=False)\n",
    "    print(train_loss, val_loss)\n",
    "    print('Train Loss-%.4f Validation Loss-%.4f '%\n",
    "          (train_loss, val_loss))\n",
    "#     print('Val Loss-%.4f Val Accuracy-%.4f Val Precision-%.4f Val Recall-%.4f' %\n",
    "#           (val_loss, val_acc, val_precision, val_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dd4a6cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:43.496997Z",
     "iopub.status.busy": "2022-06-27T07:07:43.496577Z",
     "iopub.status.idle": "2022-06-27T07:07:43.551382Z",
     "shell.execute_reply": "2022-06-27T07:07:43.550235Z"
    },
    "papermill": {
     "duration": 0.076793,
     "end_time": "2022-06-27T07:07:43.553801",
     "exception": false,
     "start_time": "2022-06-27T07:07:43.477008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 118.13it/s]\n"
     ]
    }
   ],
   "source": [
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "test_df = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4c507f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:43.597274Z",
     "iopub.status.busy": "2022-06-27T07:07:43.596794Z",
     "iopub.status.idle": "2022-06-27T07:07:43.611956Z",
     "shell.execute_reply": "2022-06-27T07:07:43.610861Z"
    },
    "papermill": {
     "duration": 0.037732,
     "end_time": "2022-06-27T07:07:43.614406",
     "exception": false,
     "start_time": "2022-06-27T07:07:43.576674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e27dd5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:43.654600Z",
     "iopub.status.busy": "2022-06-27T07:07:43.654214Z",
     "iopub.status.idle": "2022-06-27T07:07:44.250937Z",
     "shell.execute_reply": "2022-06-27T07:07:44.249829Z"
    },
    "papermill": {
     "duration": 0.619977,
     "end_time": "2022-06-27T07:07:44.253415",
     "exception": false,
     "start_time": "2022-06-27T07:07:43.633438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = clean_text(test_df, nlp, 'source')\n",
    "test_dict_length, test_word_dict = make_word_dict(test)\n",
    "test_max_length = find_max_length(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93165dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:44.296668Z",
     "iopub.status.busy": "2022-06-27T07:07:44.296273Z",
     "iopub.status.idle": "2022-06-27T07:07:44.304859Z",
     "shell.execute_reply": "2022-06-27T07:07:44.303966Z"
    },
    "papermill": {
     "duration": 0.030855,
     "end_time": "2022-06-27T07:07:44.306775",
     "exception": false,
     "start_time": "2022-06-27T07:07:44.275920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PythonDataset3(Dataset):\n",
    "    def __init__(self, df, word_dict, max_length):\n",
    "        self.df = df\n",
    "        self.word_dict = word_dict\n",
    "        self.max_len = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "#         print(row)\n",
    "        content = row['cleaned'].split(' ')\n",
    "        \n",
    "        # find the idx that is asscoiated with the particular word\n",
    "        content_idxs = [self.word_dict[word] for word in content]\n",
    "        # front pad the sentence \n",
    "        cleaned_content_arr = np.array(content_idxs)\n",
    "        zeros_arr = np.zeros(max_length - len(content))\n",
    "        padded_arr = np.concatenate([zeros_arr, cleaned_content_arr])\n",
    "        \n",
    "        x = torch.LongTensor(padded_arr) \n",
    "        x2 = torch.tensor(row['rank']).float()\n",
    "        \n",
    "        # embedding likes long tensors\n",
    "        return x, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f685bf7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:44.345830Z",
     "iopub.status.busy": "2022-06-27T07:07:44.345443Z",
     "iopub.status.idle": "2022-06-27T07:07:44.350797Z",
     "shell.execute_reply": "2022-06-27T07:07:44.349747Z"
    },
    "papermill": {
     "duration": 0.027269,
     "end_time": "2022-06-27T07:07:44.353085",
     "exception": false,
     "start_time": "2022-06-27T07:07:44.325816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = PythonDataset3(test, test_word_dict, test_max_length)\n",
    "\n",
    "test_dl = DataLoader(test_ds, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d94a0eac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:44.392200Z",
     "iopub.status.busy": "2022-06-27T07:07:44.391384Z",
     "iopub.status.idle": "2022-06-27T07:07:44.429129Z",
     "shell.execute_reply": "2022-06-27T07:07:44.428267Z"
    },
    "papermill": {
     "duration": 0.060076,
     "end_time": "2022-06-27T07:07:44.431780",
     "exception": false,
     "start_time": "2022-06-27T07:07:44.371704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 312.76it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "pred_lst = list()\n",
    "for x, x2 in tqdm(test_dl):\n",
    "\n",
    "    y_pred = model(x, x2)\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    pred_lst.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b605528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:44.473863Z",
     "iopub.status.busy": "2022-06-27T07:07:44.473465Z",
     "iopub.status.idle": "2022-06-27T07:07:44.480064Z",
     "shell.execute_reply": "2022-06-27T07:07:44.478895Z"
    },
    "papermill": {
     "duration": 0.029475,
     "end_time": "2022-06-27T07:07:44.482367",
     "exception": false,
     "start_time": "2022-06-27T07:07:44.452892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df['pred_val'] = np.concatenate( pred_lst, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "773c3bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:44.521467Z",
     "iopub.status.busy": "2022-06-27T07:07:44.521049Z",
     "iopub.status.idle": "2022-06-27T07:07:44.527352Z",
     "shell.execute_reply": "2022-06-27T07:07:44.526259Z"
    },
    "papermill": {
     "duration": 0.028313,
     "end_time": "2022-06-27T07:07:44.529490",
     "exception": false,
     "start_time": "2022-06-27T07:07:44.501177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred_val\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80ca8b14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:44.568612Z",
     "iopub.status.busy": "2022-06-27T07:07:44.568229Z",
     "iopub.status.idle": "2022-06-27T07:07:44.582786Z",
     "shell.execute_reply": "2022-06-27T07:07:44.581989Z"
    },
    "papermill": {
     "duration": 0.036493,
     "end_time": "2022-06-27T07:07:44.584700",
     "exception": false,
     "start_time": "2022-06-27T07:07:44.548207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c f9893819 c6cd22db ba55e576 1372ae9b 39e937ec 90ed07ab e25aa9bd 7f388a41 0a226b6a 2843a25a 8cb8d28a 06dbf8cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d 7f270e34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>8679f842 aafc3d23 4ae17669 80e077ec 8ce62db4 b190ebb4 bac960d3 f9e38e5a ed415c3c ea06b4d0 322850af 50bc28b3 c069ed33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02 d22526d1 3ae7ece3 eb293dfc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                               cell_order\n",
       "0  0009d135ece78d     ddfd239c f9893819 c6cd22db ba55e576 1372ae9b 39e937ec 90ed07ab e25aa9bd 7f388a41 0a226b6a 2843a25a 8cb8d28a 06dbf8cf\n",
       "1  0010483c12ba9b                                54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d 7f270e34\n",
       "2  0010a919d60e4f  8679f842 aafc3d23 4ae17669 80e077ec 8ce62db4 b190ebb4 bac960d3 f9e38e5a ed415c3c ea06b4d0 322850af 50bc28b3 c069ed33...\n",
       "3  0028856e09c5b7                                                                                      012c9d02 d22526d1 3ae7ece3 eb293dfc"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6443e2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T07:07:44.625093Z",
     "iopub.status.busy": "2022-06-27T07:07:44.624665Z",
     "iopub.status.idle": "2022-06-27T07:07:44.631499Z",
     "shell.execute_reply": "2022-06-27T07:07:44.630610Z"
    },
    "papermill": {
     "duration": 0.030047,
     "end_time": "2022-06-27T07:07:44.633765",
     "exception": false,
     "start_time": "2022-06-27T07:07:44.603718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac6215",
   "metadata": {
    "papermill": {
     "duration": 0.018573,
     "end_time": "2022-06-27T07:07:44.671556",
     "exception": false,
     "start_time": "2022-06-27T07:07:44.652983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.639616,
   "end_time": "2022-06-27T07:07:48.121330",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-27T07:06:58.481714",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
